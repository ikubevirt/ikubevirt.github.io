# GPU概览

## 研发背景

随着AI技术的发展，贝壳内部也有越来越多的场景使用到了机器学习算法提供服务，如每天上班的人脸识别、家装现场的鱼眼监控、经纪人的语音识别以及交易过程中的图片和文本识别等。机器学习模型从开发到应用的基本流程如图1所示，基本可以分为数据准备，模型开发，模型应用等三个大阶段，其中模型开发的训练和模型应用的推理阶段涉及大量的矩阵运算，特别是深度学习模型。因此在这些场景中会使用对矩阵运算具有天生优势的GPU设备来加速。

但是并不是所有阶段都需要大量GPU算力支持，如在算法工程师调试模型阶段，GPU主要用于验证模型是否合理，验证之后的训练才需要大量的算力；在模型推理预测时只有前向传播计算。这些场景下如果独占一张GPU卡会导致资源利用率很低，同时，线上服务又具备波峰和波谷的情况，会进一步降低资源利用率，造成资源浪费，增大AI服务成本。

## 研究内容

以下研究内容细分了几项供读者学习和参考。

### 快速了解

[cards cols="3" image-tags(./docs/assets/data/gpu/gpu.yaml)]

### Operators

[cards cols="3" image-tags(./docs/assets/data/gpu/operator.yaml)]

